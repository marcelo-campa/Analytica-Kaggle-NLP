{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio Natural Language Processing with Disaster Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = zipfile.ZipFile('./data/nlp-getting-started.zip')\n",
    "train = pd.read_csv(zf.open('train.csv'))\n",
    "test = pd.read_csv(zf.open('test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A coluna 'keyword' tem potencial, ja que no treino e no teste tem poucos dados faltantes\n",
    "    - Preencher com label 'faltante' nos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HAPPENING',\n",
       " 'NOW',\n",
       " '-',\n",
       " 'HATZOLAH',\n",
       " 'EMS',\n",
       " 'AMBULANCE',\n",
       " 'RESPONDING',\n",
       " 'WITH',\n",
       " 'DUAL',\n",
       " 'SIRENS',\n",
       " 'AND\\x89Û_',\n",
       " 'https',\n",
       " ':',\n",
       " '//t.co/SeK6MQ6NJF']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(train['text'][200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_nltk = list(stopwords.words('english'))\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(train['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_matrix(count_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Our',\n",
       " 'Deeds',\n",
       " 'are',\n",
       " 'the',\n",
       " 'Reason',\n",
       " 'of',\n",
       " 'this',\n",
       " '#',\n",
       " 'earthquake',\n",
       " 'May',\n",
       " 'ALLAH',\n",
       " 'Forgive',\n",
       " 'us',\n",
       " 'all']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checando a tokenizacao\n",
    "\n",
    "word_tokenize(train['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def tweet_tokenize_column(df, column):\n",
    "    \"\"\" \n",
    "        This function gets the Dataframe and the name of a column (String) containing texts (Strings) and returns\n",
    "        a list of lists containing the tokenized text. It also turns every token to it's lower form.\n",
    "        \n",
    "        Input: Pandas DataFrame, String\n",
    "        Return: Nested List\n",
    "    \"\"\"\n",
    "    \n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    \n",
    "    # List of sentences\n",
    "    list_sent = [tweet_tokenizer.tokenize(sent) for sent in df[column].values]\n",
    "    \n",
    "    # List of sentences excluding stopword tokens\n",
    "    list_sent_no_stop = [[token.lower() \n",
    "                           for token in sent \n",
    "                           if token not in stopwords.words('english')] \n",
    "                           for sent in list_sent]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return list_sent_no_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sent_train = tweet_tokenize_column(train,'text')\n",
    "tokenized_sent_test = tweet_tokenize_column(test,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['our', 'deeds', 'reason', '#earthquake', 'may', 'allah', 'forgive', 'us'],\n",
       " ['forest', 'fire', 'near', 'la', 'ronge', 'sask', '.', 'canada']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sent_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['just', 'happened', 'terrible', 'car', 'crash'],\n",
       " ['heard',\n",
       "  '#earthquake',\n",
       "  'different',\n",
       "  'cities',\n",
       "  ',',\n",
       "  'stay',\n",
       "  'safe',\n",
       "  'everyone',\n",
       "  '.']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sent_test[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o TF-IDF nos datasets. Esses tem como caracteristicas:\n",
    "- Contem palavras somente em letra minuscula\n",
    "- Nao tem stopwords\n",
    "- Foi tokenizado com o TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafael\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['#abha',\n",
       " '#ableg',\n",
       " '#abomb',\n",
       " '#abstorm',\n",
       " '#accident',\n",
       " '#accidentalprophecy',\n",
       " '#acenewsdesk',\n",
       " '#achedin',\n",
       " '#act',\n",
       " '#actionmoviestaughtus']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Funcao auxiliar para bypass do tokenizador, uma vez que este passo ja foi feito.\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "tfidf_train = TfidfVectorizer(tokenizer=identity_tokenizer, stop_words='english', lowercase=False)    \n",
    "tfidf_train_fit = tfidf_train.fit_transform(tokenized_sent_train)\n",
    "\n",
    "tfidf_train.get_feature_names()[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#amtrak',\n",
       " '#amwriting',\n",
       " '#anchorage',\n",
       " '#ancient',\n",
       " '#animalrescue',\n",
       " '#anime',\n",
       " '#anonymous',\n",
       " '#anthrax',\n",
       " '#anti-terrorism',\n",
       " '#anticipate']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_test = TfidfVectorizer(tokenizer=identity_tokenizer, stop_words='english', lowercase=False)    \n",
    "tfidf_test_fit = tfidf_test.fit_transform(tokenized_sent_test)\n",
    "\n",
    "tfidf_test.get_feature_names()[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF DataFrame dimensions: (7613, 22900)\n",
      "\n",
      "TF-IDF Number or Features: 22900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF DataFrame dimensions: {}\\n\".format(tfidf_train_fit.toarray().shape))\n",
    "print(\"TF-IDF Number or Features: {}\\n\".format(len(tfidf_train.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz sentido, ja que o numero de colunas do ``tfidf_train_fit`` corresponde ao numero de tokens, e a contagem do ``tfidf_train.get_feature_names()`` tambem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dataframes de treino e teste pos TF-IDF\n",
    "\n",
    "tfidf_train_df = pd.DataFrame(tfidf_train_fit.toarray(), columns=tfidf_train.get_feature_names())\n",
    "tfidf_test_df = pd.DataFrame(tfidf_test_fit.toarray(), columns=tfidf_test.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acrescentando o target ao dataframe\n",
    "\n",
    "tfidf_train_df[\"target_column\"] = train[\"target\"]\n",
    "tfidf_test_df[\"target_column\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>##book</th>\n",
       "      <th>##fukushima</th>\n",
       "      <th>##youtube</th>\n",
       "      <th>#0215</th>\n",
       "      <th>#034</th>\n",
       "      <th>#039</th>\n",
       "      <th>#06</th>\n",
       "      <th>#09</th>\n",
       "      <th>...</th>\n",
       "      <th>ûò800000</th>\n",
       "      <th>ûòthe</th>\n",
       "      <th>ûòåêcnbc</th>\n",
       "      <th>ûó</th>\n",
       "      <th>ûóher</th>\n",
       "      <th>ûókody</th>\n",
       "      <th>ûónegligence</th>\n",
       "      <th>ûótech</th>\n",
       "      <th>ûówe</th>\n",
       "      <th>target_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     !    #  ##book  ##fukushima  ##youtube  #0215  #034  #039  #06  #09  ...  \\\n",
       "0  0.0  0.0     0.0          0.0        0.0    0.0   0.0   0.0  0.0  0.0  ...   \n",
       "1  0.0  0.0     0.0          0.0        0.0    0.0   0.0   0.0  0.0  0.0  ...   \n",
       "2  0.0  0.0     0.0          0.0        0.0    0.0   0.0   0.0  0.0  0.0  ...   \n",
       "\n",
       "   ûò800000  ûòthe  ûòåêcnbc   ûó  ûóher  ûókody  ûónegligence  ûótech  ûówe  \\\n",
       "0       0.0    0.0       0.0  0.0    0.0     0.0           0.0     0.0   0.0   \n",
       "1       0.0    0.0       0.0  0.0    0.0     0.0           0.0     0.0   0.0   \n",
       "2       0.0    0.0       0.0  0.0    0.0     0.0           0.0     0.0   0.0   \n",
       "\n",
       "   target_column  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "\n",
       "[3 rows x 22901 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>#039</th>\n",
       "      <th>#05</th>\n",
       "      <th>#0518</th>\n",
       "      <th>#12k</th>\n",
       "      <th>#16</th>\n",
       "      <th>#1oak</th>\n",
       "      <th>#21dayfix</th>\n",
       "      <th>#26</th>\n",
       "      <th>...</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûò7</th>\n",
       "      <th>ûòdon</th>\n",
       "      <th>ûó</th>\n",
       "      <th>ûócategorically</th>\n",
       "      <th>ûókaiserjaegers</th>\n",
       "      <th>ûókill</th>\n",
       "      <th>ûówe</th>\n",
       "      <th>ûówere</th>\n",
       "      <th>target_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 12806 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     !    #  #039  #05  #0518  #12k  #16  #1oak  #21dayfix  #26  ...   ûò  \\\n",
       "0  0.0  0.0   0.0  0.0    0.0   0.0  0.0    0.0        0.0  0.0  ...  0.0   \n",
       "1  0.0  0.0   0.0  0.0    0.0   0.0  0.0    0.0        0.0  0.0  ...  0.0   \n",
       "2  0.0  0.0   0.0  0.0    0.0   0.0  0.0    0.0        0.0  0.0  ...  0.0   \n",
       "\n",
       "   ûò7  ûòdon   ûó  ûócategorically  ûókaiserjaegers  ûókill  ûówe  ûówere  \\\n",
       "0  0.0    0.0  0.0              0.0              0.0     0.0   0.0     0.0   \n",
       "1  0.0    0.0  0.0              0.0              0.0     0.0   0.0     0.0   \n",
       "2  0.0    0.0  0.0              0.0              0.0     0.0   0.0     0.0   \n",
       "\n",
       "   target_column  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "\n",
       "[3 rows x 12806 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.384545\n",
       "1       0.000000\n",
       "2       0.000000\n",
       "3       0.000000\n",
       "4       0.000000\n",
       "          ...   \n",
       "7608    0.000000\n",
       "7609    0.000000\n",
       "7610    0.000000\n",
       "7611    0.000000\n",
       "7612    0.000000\n",
       "Name: reason, Length: 7613, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train_df['reason']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos acima que a palavra 'reason' tem score na primeira sentenca. Isso e coerente ja que ela aparece na primeira linha do dataframe de treino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do\n",
    "- Selecionar variaveis mais importantes (Chi^2 | Informacao Mutua)\n",
    "- Selecionar colunas contendo essas variaveis tanto no treino quanto no teste\n",
    "    - As colunas devem estar na mesma ordem!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
