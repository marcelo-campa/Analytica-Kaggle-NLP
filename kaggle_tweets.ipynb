{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio Natural Language Processing with Disaster Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = zipfile.ZipFile('./data/nlp-getting-started.zip')\n",
    "train = pd.read_csv(zf.open('train.csv'))\n",
    "test = pd.read_csv(zf.open('test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A coluna 'keyword' tem potencial, ja que no treino e no teste tem poucos dados faltantes\n",
    "    - Preencher com label 'faltante' nos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(train['text'][200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_nltk = list(stopwords.words('english'))\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(train['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_matrix(count_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando a tokenizacao\n",
    "\n",
    "word_tokenize(train['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def tweet_tokenize_column(df, column):\n",
    "    \"\"\" \n",
    "        This function gets the Dataframe and the name of a column (String) containing texts (Strings) and returns\n",
    "        a list of lists containing the tokenized text. It also turns every token to it's lower form.\n",
    "        \n",
    "        Input: Pandas DataFrame, String\n",
    "        Return: Nested List\n",
    "    \"\"\"\n",
    "    \n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    \n",
    "    # List of sentences\n",
    "    list_sent = [tweet_tokenizer.tokenize(sent) for sent in df[column].values]\n",
    "    \n",
    "    # List of sentences excluding stopword tokens\n",
    "    list_sent_no_stop = [[token.lower() \n",
    "                           for token in sent \n",
    "                           if token not in stopwords.words('english')] \n",
    "                           for sent in list_sent]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return list_sent_no_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sent_train = tweet_tokenize_column(train,'text')\n",
    "tokenized_sent_test = tweet_tokenize_column(test,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sent_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sent_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sent_all = tokenized_sent_train + tokenized_sent_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o TF-IDF nos datasets. Esses tem como caracteristicas:\n",
    "- Contem palavras somente em letra minuscula\n",
    "- Nao tem stopwords\n",
    "- Foi tokenizado com o TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao auxiliar para bypass do tokenizador, uma vez que este passo ja foi feito.\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "tfidf_all = TfidfVectorizer(tokenizer=identity_tokenizer, stop_words='english', lowercase=False)    \n",
    "tfidf_all_fit = tfidf_all.fit_transform(tokenized_sent_all)\n",
    "\n",
    "tfidf_all.get_feature_names()[1000:1002]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_all.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#       token1 token2 token3\n",
    "# train1\n",
    "# train2\n",
    "# .\n",
    "# .\n",
    "# trainN\n",
    "# test1\n",
    "# test2\n",
    "# .\n",
    "# .\n",
    "# testN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(\"TF-IDF DataFrame dimensions: {}\\n\".format(tfidf_train_fit.toarray().shape))\n",
    "# print(\"TF-IDF Number or Features: {}\\n\".format(len(tfidf_train.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz sentido, ja que o numero de colunas do ``tfidf_train_fit`` corresponde ao numero de tokens, e a contagem do ``tfidf_train.get_feature_names()`` tambem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_all_df = pd.DataFrame(tfidf_all_fit.toarray(), columns=tfidf_all.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_df = tfidf_all_df[:len(train)]\n",
    "\n",
    "tfidf_test_df = tfidf_all_df[len(train):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_df[\"target_column\"] = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_df['target_column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi = mutual_info_classif(tfidf_train_df_int.drop(\"target_column\", axis=1), tfidf_train_df_int[\"target_column\"])\n",
    "# mi = pd.Series(mi)\n",
    "# mi.index = intersect_columns\n",
    "# mi.sort_values(ascending=False, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "X = tfidf_train_df.drop(\"target_column\", axis=1)\n",
    "y = tfidf_train_df[\"target_column\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=16)\n",
    "\n",
    "clf = LogisticRegression(random_state=16)\n",
    "\n",
    "scores_logistic = cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_logistic.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf.fit(X,y)\n",
    "\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "print('Training accuracy is {}'.format(accuracy_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submissao\n",
    "\n",
    "sample_submission = pd.read_csv(zf.open('sample_submission.csv'))\n",
    "\n",
    "y_sub = clf.predict(tfidf_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sample_submission.copy()\n",
    "sub['target'] = y_sub\n",
    "sub.set_index('id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"./submissions/sub_01.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecao de atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, chi2\n",
    "\n",
    "chi = chi2(X,y)\n",
    "chi = pd.Series(chi[0])\n",
    "chi.index = X.columns\n",
    "chi.sort_values(ascending=False, inplace=True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi.to_csv(\"./data/chi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atts = np.linspace(100,10000,100)\n",
    "# list_scores = []\n",
    "# list_var = []\n",
    "\n",
    "# for att in tqdm(atts):\n",
    "    \n",
    "#     list_scores.append(cross_val_score(clf, X[chi[:int(att)].index], y, cv=3).mean())\n",
    "#     list_var.append(cross_val_score(clf, X[chi[:int(att)].index], y, cv=3).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# int_atts = [int(att) for att in atts]\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# sns.set()\n",
    "# plt.figure(figsize=(14,7))\n",
    "# sns.lineplot(y=list_scores, x=int_atts)\n",
    "# # plt.axvline(x=int_atts[np.array(list_scores[5:]).argmax()+5], color='r')\n",
    "# # plt.xticks(ticks=np.arange(0.00, 0.25, 0.01))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set()\n",
    "# plt.figure(figsize=(14,7))\n",
    "# sns.lineplot(y=list_var, x=int_atts)\n",
    "# # plt.axvline(x=int_atts[np.array(list_var[5:]).argmin()+5], color='r')\n",
    "# # plt.xticks(ticks=np.arange(0.00, 0.25, 0.01))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atts = np.linspace(100,10000,100)\n",
    "# list_scores_over = []\n",
    "\n",
    "# for att in tqdm(atts):\n",
    "#     clf.fit(X[chi[:int(att)].index],y)\n",
    "#     y_pred = clf.predict(X[chi[:int(att)].index])\n",
    "#     acc = accuracy_score(y, y_pred)\n",
    "    \n",
    "#     list_scores_over.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_atts = [int(att) for att in atts]\n",
    "\n",
    "# sns.set()\n",
    "# plt.figure(figsize=(14,7))\n",
    "# sns.lineplot(y=list_scores_over, x=int_atts)\n",
    "# # plt.axvline(x=int_atts[np.array(list_scores[5:]).argmax()+5], color='r')\n",
    "# # plt.xticks(ticks=np.arange(0.00, 0.25, 0.01))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atts = np.linspace(100,10000,100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_scores_tts = []\n",
    "\n",
    "# for att in tqdm(atts):\n",
    "#     clf.fit(X_train[chi[:int(att)].index],y_train)\n",
    "#     y_pred = clf.predict(X_test[chi[:int(att)].index])\n",
    "#     acc = accuracy_score(y_test , y_pred)\n",
    "    \n",
    "#     list_scores_tts.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_atts = [int(att) for att in atts]\n",
    "\n",
    "# sns.set()\n",
    "# plt.figure(figsize=(14,7))\n",
    "# sns.lineplot(y=list_scores_tts, x=int_atts)\n",
    "# # plt.axvline(x=int_atts[np.array(list_var[5:]).argmin()+5], color='r')\n",
    "# # plt.xticks(ticks=np.arange(0.00, 0.25, 0.01))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_atts = [int(att) for att in atts]\n",
    "# int_atts[np.array(list_scores_atts).argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train[chi[:3800].index],y_train)\n",
    "y_pred = clf.predict(X_test[chi[:3800].index])\n",
    "acc = accuracy_score(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub_chi = clf.predict(tfidf_test_df[chi[:3800].index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_chi = sample_submission.copy()\n",
    "sub_chi['target'] = y_sub_chi\n",
    "sub_chi.set_index('id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_chi.to_csv(\"./submissions/sub_chi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_svc = SVC()\n",
    "clf_svc.fit(X_train[chi[:3800].index],y_train)\n",
    "y_pred = clf_svc.predict(X_test[chi[:3800].index])\n",
    "acc = accuracy_score(y_test , y_pred)\n",
    "\n",
    "print('Training accuracy is {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc.fit(tfidf_train_df[chi[:3800].index],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub_svc = clf_svc.predict(tfidf_test_df[chi[:3800].index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_svc = sample_submission.copy()\n",
    "sub_svc['target'] = y_sub_svc\n",
    "sub_svc.set_index('id',inplace=True)\n",
    "\n",
    "sub_svc.to_csv(\"./submissions/sub_svc_overfit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atts = [1000,3000,5000]\n",
    "# list_scores_svc = []\n",
    "\n",
    "# for att in tqdm(atts):\n",
    "#     clf_svc.fit(X_train[chi[:int(att)].index],y_train)\n",
    "#     y_pred = clf_svc.predict(X_test[chi[:int(att)].index])\n",
    "#     acc = accuracy_score(y_test , y_pred)\n",
    "    \n",
    "#     list_scores_svc.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "with nlp.disable_pipes():\n",
    "    train_vecs = pd.DataFrame(np.array([nlp(text).vector for text in train.text])) # doc vectors for training set\n",
    "    test_vecs = pd.DataFrame(np.array([nlp(text).vector for text in test.text])) # doc vectors for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = mutual_info_classif(train_vecs,train.target)\n",
    "mi = pd.Series(mi)\n",
    "mi.index = train_vecs.columns\n",
    "mi.sort_values(ascending=False, inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_word_vec_train, X_word_vec_test, y_word_vec_train, y_word_vec_test = train_test_split(train_vecs, train.target.values, test_size=0.33, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "\n",
    "atts = np.linspace(1, 299, 299)\n",
    "list_scores_svc = []\n",
    "\n",
    "for att in tqdm(atts):\n",
    "    svc.fit(X_word_vec_train[mi[:int(att)].index].values, y_word_vec_train)\n",
    "    y_pred = svc.predict(X_word_vec_test[mi[:int(att)].index].values)\n",
    "    acc = accuracy_score(y_word_vec_test , y_pred)\n",
    "    \n",
    "    list_scores_svc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "int_atts = [int(att) for att in atts]\n",
    "\n",
    "sns.set()\n",
    "plt.figure(figsize=(14,7))\n",
    "sns.lineplot(y=list_scores_svc, x=atts)\n",
    "plt.xticks(ticks=np.arange(0.00, 0.25, 0.01))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(train_vecs.values, train.target)\n",
    "y_pred = svc.predict(test_vecs.values)\n",
    "\n",
    "sub_svc = sample_submission.copy()\n",
    "sub_svc['target'] = y_sub_svc\n",
    "sub_svc.set_index('id',inplace=True)\n",
    "\n",
    "sub_svc.to_csv(\"./submissions/sub_svc_word_vec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# tree = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "# scores_tree = cross_val_score(tree, X, y, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_tree.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_tree = tfidf_df.loc[:,~(tfidf_df.columns == 'target_column')]\n",
    "# Y_tree = tfidf_df.target_column\n",
    "\n",
    "# accuracy_test = []\n",
    "\n",
    "# kf = KFold(n_splits=10)\n",
    "\n",
    "# X = X_tree.values\n",
    "# y = Y_tree.values\n",
    "\n",
    "# for train_index, test_index in kf.split(X_tree):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "#     tree = DecisionTreeClassifier(criterion=\"entropy\", ccp_alpha=0.001226509672564484)\n",
    "    \n",
    "#     tree.fit(X_train, y_train)\n",
    "#     y_test_pred = tree.predict(X_test)\n",
    "#     accuracy_test.append(metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "# st.t.interval(0.99, len(accuracy_test) - 1, loc=np.mean(accuracy_test), scale=st.sem(accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do\n",
    "- Selecionar variaveis mais importantes (Chi^2 | Informacao Mutua)\n",
    "- Selecionar colunas contendo essas variaveis tanto no treino quanto no teste\n",
    "- Testar selecao de variaveis antes para todos os tokens do treino\n",
    "- Testar outros modelos (SVC, NaiveBayes, RidgeClassifier, ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
